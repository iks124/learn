# 基于不同模型架构的猫狗分类实验报告

## 一、实验目的

本次实验旨在基于`model.py`中包含的 CNN、RNN、DNN 三类文本建模架构，结合训练结果（来源于`training_results.json`训练日志），对比分析不同模型在文本任务中的表现，诊断模型训练过程中存在的问题，进而确定最优模型方案，并提出针对性的改进建议，为后续模型优化提供依据。

## 二、实验设置与过程

`model.py`中的模型架构包含 CNN、RNN、DNN 三类建模架构。`training_results.json`包含结果数据。重点关注各模型在验证集上的准确率（val\_acc）和损失（val\_loss）变化情况，以此作为分析模型性能的核心依据。在数据统计过程中，我逐轮记录各模型的验证集指标，筛选出每个模型的最佳验证准确率、最低验证损失及对应的轮次，同时观察模型在训练后期的指标变化趋势，判断是否存在过拟合、收敛缓慢等问题。

## 三、实验结果与分析

### （一）各模型关键验证集结果



1. **CNN 模型**：在本次实验中，CNN 模型表现较为突出。其最佳验证准确率（val\_acc）达到 0.680，出现在训练的第 10 轮；而最低验证损失（val\_loss）约为 0.597，在第 3 轮就已出现。不过，从第 3 轮之后，我发现 CNN 模型的验证损失开始上升，准确率则出现小幅波动，到了训练后期，明显呈现出过拟合的迹象。

2. **RNN 模型**：RNN 模型的整体表现稍逊于 CNN。它的最佳验证准确率为 0.608，同样在第 10 轮出现；最低验证损失约为 0.670，出现在第 4 轮附近。在训练过程中，我观察到 RNN 模型的性能提升速度较为缓慢，而且到了后期，各项指标震荡明显，稳定性欠佳。

3. **DNN 模型**：DNN 模型在本次实验中表现最差，整体性能接近随机起点。其最佳验证准确率仅为 0.560，出现在第 5 轮，之后验证准确率便维持在 0.50-0.55 之间。这一结果表明，DNN 模型在捕获序列 / 局部模式方面能力不足，难以满足该文本任务的需求。

### （二）实验结果汇总表

为了更清晰地对比各模型性能，我将关键实验结果整理成如下表格：



| 模型  | 最佳轮次 | 最佳验证准确率   | 最低验证损失 (观测轮次) | 训练现象判断           |
| --- | ---- | --------- | ------------- | ---------------- |
| CNN | 10   | **0.680** | 0.597（第 3 轮）  | 中后期过拟合、准确率涨幅有限   |
| RNN | 10   | 0.608     | 0.670（第 4 轮）  | 收敛慢、对正则化 / 优化较敏感 |
| DNN | 5    | 0.560     | 0.686（第 9 轮）  | 学不到序列结构，表现垫底     |

### （三）结果分析

从上述结果来看，在相同的训练轮次下，三类模型的性能呈现出 “CNN> RNN > DNN” 的明显差距。我认为，CNN 模型能取得最高验证准确率，核心原因在于其擅长提取局部 n-gram 卷积特征，这种特性与本次文本任务的需求高度契合；而 RNN 模型由于自身结构特点，在处理序列数据时收敛速度较慢，且对正则化和优化手段较为敏感，导致性能稍弱；DNN 模型作为纯多层感知机，缺乏对序列结构的有效捕获能力，因此在该任务中表现垫底。另外，CNN 模型在第 3 轮后出现的 “损失反弹” 现象，是典型的过拟合信号，这也意味着如果继续无约束地训练该模型，大概率无法带来稳定的性能提升。

## 四、实验结论



1. 模型性能排序明确：在本次实验涉及的三类模型中，CNN 模型的性能最优，最佳验证准确率达到 0.680，是当前任务下的最优选择；RNN 模型次之，DNN 模型表现最差，难以满足任务需求。

2. 过拟合问题凸显：CNN 模型在训练中后期出现明显过拟合，具体表现为验证损失上升而准确率小幅波动，这一问题若不解决，会严重影响模型的泛化能力。

3. 模型特性与任务匹配度关键：实验结果充分表明，模型对序列 / 局部模式的建模能力直接影响其在文本任务中的表现，只有模型特性与任务需求高度匹配，才能发挥出较好的性能。

## 五、改进建议

基于本次实验结果和发现的问题，我提出以下务实、可操作的改进建议：



1. **引入提前停止机制**：我建议以验证损失为依据触发 early stopping，设置耐心值（patience）为 2-3。这样一来，CNN 模型或许能在第 3-5 轮就取得更稳健的泛化性能，避免后期过拟合的加剧。

2. **加强正则化与优化数据处理**：

* 适度增大 Dropout 比例或采用权重衰减（L2），以此抑制过拟合；

* 对于词向量 / 子词嵌入，我计划采用 “冻结 + 微调” 的两阶段策略，在保证嵌入质量的同时降低过拟合风险；

* 若本次任务为文本分类，可引入数据增强手段，如 EDA、回译、同义替换等，也可尝试 Mixup/CutMix-Text 变体，丰富训练数据。

1. **优化优化器与学习率策略**：我打算使用 “AdamW + 线性预热 + 余弦退火” 的组合方案；针对 RNN 模型训练后期震荡明显的问题，尝试加入 gradient clipping（如设置为 1.0），提升模型训练的稳定性。

2. **调整模型结构**：

* CNN 模型：采用多核尺寸并行（如 k={2,3,4,5}），并加入通道注意力（SE/CBAM），在增强特征提取能力的同时控制参数量；

* RNN 模型：将其改造为 BiLSTM + Attention 的结构，缩短依赖路径，提升对序列信息的捕获效率；

* DNN 模型：若必须保留该模型，我会在其输入层前置平均池 / 最大池的词向量金字塔，或采用 TF-IDF/SIF 句向量作为输入；若无需强制保留，建议直接淘汰该模型。

## 六、结语

综合本次实验的训练日志数据，我认为 CNN 模型是当前任务下明确的一线方案，但该模型已暴露过拟合拐点。因此，可以围绕 “早停 + 正则 + 轻量结构改造” 开展小步快跑式的消融实验；若需要进一步提升性能上限，再引入轻量 Transformer 作为对照模型，明确该任务的可达天花板。
